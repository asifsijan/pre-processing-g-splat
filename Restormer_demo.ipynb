{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeGEHo0VjpY5"
      },
      "source": [
        "# Restormer: Efficient Transformer for High-Resolution Image Restoration (CVPR 2022 -- Oral) [![paper](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2111.09881)\n",
        "\n",
        "<hr />\n",
        "\n",
        "This is a demo to run Restormer on you own images for the following tasks\n",
        "- Real Image Denoising\n",
        "- Single-Image Defocus Deblurring\n",
        "- Single-Image Motion Deblurring\n",
        "- Image Deraining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRd46QaXlklQ"
      },
      "source": [
        "# 1. Setup\n",
        "- First, in the **Runtime** menu -> **Change runtime type**, make sure to have ```Hardware Accelerator = GPU```\n",
        "- Clone repo and install dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLDZ9t1pm9JZ",
        "outputId": "4c7bb315-d633-4b4a-f84c-e547c371c970"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Cloning into 'Restormer'...\n",
            "remote: Enumerating objects: 309, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 309 (delta 67), reused 56 (delta 56), pack-reused 202 (from 1)\u001b[K\n",
            "Receiving objects: 100% (309/309), 1.56 MiB | 25.75 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n",
            "/content/Restormer\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install einops\n",
        "\n",
        "if os.path.isdir('Restormer'):\n",
        "  !rm -r Restormer\n",
        "\n",
        "# Clone Restormer\n",
        "!git clone https://github.com/swz30/Restormer.git\n",
        "%cd Restormer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXxtBPA1tGxL"
      },
      "source": [
        "# 2. Define Task and Download Pre-trained Models\n",
        "Uncomment the task you would like to perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM4ksCkZtqUA",
        "outputId": "a7f17114-a310-4d89-d76e-b70ab48ce72e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-15 20:21:38--  https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/55c7bcd2-cb39-4d8a-adc4-acf6f6131c27?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250416%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250416T012138Z&X-Amz-Expires=300&X-Amz-Signature=4e8f77408811e603bda4f2d15eca0a354e1dde767e1c3aca5ed919e5b51c5e15&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmotion_deblurring.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-15 20:21:38--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/418793252/55c7bcd2-cb39-4d8a-adc4-acf6f6131c27?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250416%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250416T012138Z&X-Amz-Expires=300&X-Amz-Signature=4e8f77408811e603bda4f2d15eca0a354e1dde767e1c3aca5ed919e5b51c5e15&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dmotion_deblurring.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 104700429 (100M) [application/octet-stream]\n",
            "Saving to: ‘Motion_Deblurring/pretrained_models/motion_deblurring.pth.3’\n",
            "\n",
            "motion_deblurring.p 100%[===================>]  99.85M  6.79MB/s    in 24s     \n",
            "\n",
            "2025-04-15 20:22:03 (4.10 MB/s) - ‘Motion_Deblurring/pretrained_models/motion_deblurring.pth.3’ saved [104700429/104700429]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# task = 'Real_Denoising'\n",
        "# task = 'Single_Image_Defocus_Deblurring'\n",
        "task = 'Motion_Deblurring'\n",
        "# task = 'Deraining'\n",
        "\n",
        "# Download the pre-trained models\n",
        "if task is 'Real_Denoising':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/real_denoising.pth -P Denoising/pretrained_models\n",
        "if task is 'Single_Image_Defocus_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/single_image_defocus_deblurring.pth -P Defocus_Deblurring/pretrained_models\n",
        "if task is 'Motion_Deblurring':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/motion_deblurring.pth -P Motion_Deblurring/pretrained_models\n",
        "if task is 'Deraining':\n",
        "  !wget https://github.com/swz30/Restormer/releases/download/v1.0/deraining.pth -P Deraining/pretrained_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/csgrads/sijan003/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "NVIDIA GeForce RTX 3090 Ti\n"
          ]
        }
      ],
      "source": [
        "import torch  # You need this import at the top\n",
        "\n",
        "# Now you can check your GPU\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))  # Should show \"NVIDIA GeForce RTX 3090 Ti\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9nwA_Prt7PI"
      },
      "source": [
        "# 3. Upload Images\n",
        "Either download the sample images or upload your own images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copied input/0007.jpg to demo/sample_images/Motion_Deblurring/degraded/0007.jpg\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define task\n",
        "task = 'Motion_Deblurring'  # or 'deraining', 'deblurring', etc.\n",
        "\n",
        "# Clear the demo folder\n",
        "shutil.rmtree('demo', ignore_errors=True)\n",
        "\n",
        "# Set up input directory\n",
        "input_dir = f'demo/sample_images/{task}/degraded'\n",
        "os.makedirs(input_dir, exist_ok=True)\n",
        "\n",
        "# Copy your image to the input directory\n",
        "# Replace 'your_image.jpg' with the path to your image file\n",
        "src_image_path = 'input/0007.jpg'\n",
        "dst_image_path = os.path.join(input_dir, os.path.basename(src_image_path))\n",
        "shutil.copy(src_image_path, dst_image_path)\n",
        "\n",
        "print(f\"Copied {src_image_path} to {dst_image_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7ArqQfvBbRf"
      },
      "source": [
        "# 4. Prepare Model and Load Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Restormer(\n",
              "  (patch_embed): OverlapPatchEmbed(\n",
              "    (proj): Conv2d(3, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  )\n",
              "  (encoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "        (project_out): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(48, 254, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(254, 254, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=254, bias=False)\n",
              "        (project_out): Conv2d(127, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down1_2): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2_3): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (encoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3_4): Downsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelUnshuffle(downscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (latent): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "        (project_out): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(384, 2042, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(2042, 2042, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2042, bias=False)\n",
              "        (project_out): Conv2d(1021, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up4_3): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level3): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level3): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "        (project_out): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(192, 1020, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(1020, 1020, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1020, bias=False)\n",
              "        (project_out): Conv2d(510, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up3_2): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (reduce_chan_level2): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "  (decoder_level2): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up2_1): Upsample(\n",
              "    (body): Sequential(\n",
              "      (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (1): PixelShuffle(upscale_factor=2)\n",
              "    )\n",
              "  )\n",
              "  (decoder_level1): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (refinement): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (norm1): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (attn): Attention(\n",
              "        (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (qkv_dwconv): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
              "        (project_out): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "      (norm2): LayerNorm(\n",
              "        (body): WithBias_LayerNorm()\n",
              "      )\n",
              "      (ffn): FeedForward(\n",
              "        (project_in): Conv2d(96, 510, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (dwconv): Conv2d(510, 510, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=510, bias=False)\n",
              "        (project_out): Conv2d(255, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (output): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os  # Add this import\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from runpy import run_path\n",
        "from skimage import img_as_ubyte\n",
        "from natsort import natsorted\n",
        "from glob import glob\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "def get_weights_and_parameters(task, parameters):\n",
        "    weights = None  # Initialize weights\n",
        "    if task == 'Motion_Deblurring':\n",
        "        weights = os.path.join('Motion_Deblurring', 'pretrained_models', 'motion_deblurring.pth')\n",
        "    elif task == 'Single_Image_Defocus_Deblurring':\n",
        "        weights = os.path.join('Defocus_Deblurring', 'pretrained_models', 'single_image_defocus_deblurring.pth')\n",
        "    elif task == 'Deraining':\n",
        "        weights = os.path.join('Deraining', 'pretrained_models', 'deraining.pth')\n",
        "    elif task == 'Real_Denoising':\n",
        "        weights = os.path.join('Denoising', 'pretrained_models', 'real_denoising.pth')\n",
        "        parameters['LayerNorm_type'] = 'BiasFree'\n",
        "    \n",
        "    if weights is None:\n",
        "        raise ValueError(f\"Unknown task: {task}. Supported tasks are: Motion_Deblurring, Single_Image_Defocus_Deblurring, Deraining, Real_Denoising\")\n",
        "    \n",
        "    return weights, parameters\n",
        "\n",
        "\n",
        "# Define your task here (choose one)\n",
        "task = 'Motion_Deblurring'  # or 'Single_Image_Defocus_Deblurring', 'Deraining', 'Real_Denoising'\n",
        "\n",
        "# Get model weights and parameters\n",
        "parameters = {'inp_channels':3, 'out_channels':3, 'dim':48, 'num_blocks':[4,6,6,8], 'num_refinement_blocks':4, 'heads':[1,2,4,8], 'ffn_expansion_factor':2.66, 'bias':False, 'LayerNorm_type':'WithBias', 'dual_pixel_task':False}\n",
        "weights, parameters = get_weights_and_parameters(task, parameters)\n",
        "\n",
        "load_arch = run_path(os.path.join('basicsr', 'models', 'archs', 'restormer_arch.py'))\n",
        "model = load_arch['Restormer'](**parameters)\n",
        "model.cuda()\n",
        "\n",
        "checkpoint = torch.load(weights)\n",
        "model.load_state_dict(checkpoint['params'])\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDvxkztWDsYd"
      },
      "source": [
        "# 5. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "odPtmz_lD2Rd",
        "outputId": "ffb6bf26-c1fd-4db8-95af-511cab75ebe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ==> Running Motion_Deblurring with weights Motion_Deblurring/pretrained_models/motion_deblurring.pth\n",
            " \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 7.58 GiB (GPU 0; 23.55 GiB total capacity; 12.06 GiB already allocated; 7.13 GiB free; 14.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2860674/2715977836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mrestored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mrestored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestored\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/pre-processing-g-splat/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp_img)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0minp_enc_level1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mout_enc_level1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_level1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_enc_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0minp_enc_level2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_enc_level1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/pre-processing-g-splat/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/Desktop/pre-processing-g-splat/Restormer/basicsr/models/archs/restormer_arch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdwconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/bin/anaconda/envs/pytorch181/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    459\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 460\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 7.58 GiB (GPU 0; 23.55 GiB total capacity; 12.06 GiB already allocated; 7.13 GiB free; 14.93 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "input_dir = 'demo/sample_images/'+task+'/degraded'\n",
        "out_dir = 'demo/sample_images/'+task+'/restored'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "extensions = ['jpg', 'JPG', 'png', 'PNG', 'jpeg', 'JPEG', 'bmp', 'BMP']\n",
        "files = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "\n",
        "img_multiple_of = 8\n",
        "\n",
        "print(f\"\\n ==> Running {task} with weights {weights}\\n \")\n",
        "with torch.no_grad():\n",
        "  for filepath in tqdm(files):\n",
        "      # print(file_)\n",
        "      torch.cuda.ipc_collect()\n",
        "      torch.cuda.empty_cache()\n",
        "      img = cv2.cvtColor(cv2.imread(filepath), cv2.COLOR_BGR2RGB)\n",
        "      input_ = torch.from_numpy(img).float().div(255.).permute(2,0,1).unsqueeze(0).cuda()\n",
        "\n",
        "      # Pad the input if not_multiple_of 8\n",
        "      h,w = input_.shape[2], input_.shape[3]\n",
        "      H,W = ((h+img_multiple_of)//img_multiple_of)*img_multiple_of, ((w+img_multiple_of)//img_multiple_of)*img_multiple_of\n",
        "      padh = H-h if h%img_multiple_of!=0 else 0\n",
        "      padw = W-w if w%img_multiple_of!=0 else 0\n",
        "      input_ = F.pad(input_, (0,padw,0,padh), 'reflect')\n",
        "\n",
        "      restored = model(input_)\n",
        "      restored = torch.clamp(restored, 0, 1)\n",
        "\n",
        "      # Unpad the output\n",
        "      restored = restored[:,:,:h,:w]\n",
        "\n",
        "      restored = restored.permute(0, 2, 3, 1).cpu().detach().numpy()\n",
        "      restored = img_as_ubyte(restored[0])\n",
        "\n",
        "      filename = os.path.split(filepath)[-1]\n",
        "      cv2.imwrite(os.path.join(out_dir, filename),cv2.cvtColor(restored, cv2.COLOR_RGB2BGR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total GPU Memory: 23.99 GB\n",
            "Used GPU Memory: 16.83 GB\n",
            "Free GPU Memory: 7.16 GB\n",
            "\n",
            "PyTorch Reserved Memory:\n",
            "14.93 GB\n",
            "PyTorch Allocated Memory:\n",
            "12.06 GB\n",
            "Tue Apr 15 20:23:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3090 Ti     Off |   00000000:01:00.0  On |                  Off |\n",
            "|  0%   58C    P0            123W /  450W |   16789MiB /  24564MiB |      2%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      1918      G   /usr/lib/xorg/Xorg                            397MiB |\n",
            "|    0   N/A  N/A      2072      G   /usr/bin/gnome-shell                           81MiB |\n",
            "|    0   N/A  N/A   2807930      G   ...seed-version=20250415-050106.604000        114MiB |\n",
            "|    0   N/A  N/A   2808389      G   ...erProcess --variations-seed-version        115MiB |\n",
            "|    0   N/A  N/A   2860674      C   ...anaconda/envs/pytorch181/bin/python      16004MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from pynvml import *\n",
        "\n",
        "# Initialize NVML\n",
        "nvmlInit()\n",
        "handle = nvmlDeviceGetHandleByIndex(0)  # GPU 0\n",
        "info = nvmlDeviceGetMemoryInfo(handle)\n",
        "\n",
        "print(f\"Total GPU Memory: {info.total / 1024**3:.2f} GB\")\n",
        "print(f\"Used GPU Memory: {info.used / 1024**3:.2f} GB\")\n",
        "print(f\"Free GPU Memory: {info.free / 1024**3:.2f} GB\")\n",
        "\n",
        "# List active PyTorch allocations\n",
        "print(\"\\nPyTorch Reserved Memory:\")\n",
        "print(f\"{torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
        "print(\"PyTorch Allocated Memory:\")\n",
        "print(f\"{torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "\n",
        "# Check running processes (Linux)\n",
        "os.system(\"nvidia-smi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bwDss7ui1y2"
      },
      "source": [
        "# 6. Visualize Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jm5gyBgzlONb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results: Motion_Deblurring\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "inp_filenames = natsorted(glob(os.path.join(input_dir, '*')))\n",
        "out_filenames = natsorted(glob(os.path.join(out_dir, '*')))\n",
        "\n",
        "## Will display only first 5 images\n",
        "num_display_images = 5\n",
        "if len(inp_filenames)>num_display_images:\n",
        "  inp_filenames = inp_filenames[:num_display_images]\n",
        "  out_filenames = out_filenames[:num_display_images]\n",
        "\n",
        "print(f\"Results: {task}\")\n",
        "for inp_file, out_file in zip(inp_filenames, out_filenames):\n",
        "  degraded = cv2.cvtColor(cv2.imread(inp_file), cv2.COLOR_BGR2RGB)\n",
        "  restored = cv2.cvtColor(cv2.imread(out_file), cv2.COLOR_BGR2RGB)\n",
        "  ## Display Images\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=2)\n",
        "  dpi = fig.get_dpi()\n",
        "  fig.set_size_inches(900/ dpi, 448 / dpi)\n",
        "  plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
        "  axes[0].axis('off')\n",
        "  axes[0].imshow(degraded)\n",
        "  axes[1].axis('off')\n",
        "  axes[1].imshow(restored)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9TuiD7OtX9V"
      },
      "source": [
        "# 7. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yVqiRjflYll"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "zip_filename = f\"Restormer_{task}.zip\"\n",
        "os.system(f\"zip -r {zip_filename} demo/sample_images/{task}\")\n",
        "files.download(zip_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NYG9bFUSvEb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: demo/sample_images/Motion_Deblurring/ (stored 0%)\n",
            "  adding: demo/sample_images/Motion_Deblurring/restored/ (stored 0%)\n",
            "Zip file created at: /home/csgrads/sijan003/Desktop/pre-processing-g-splat/Restormer/Restormer_Motion_Deblurring.zip\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "zip_filename = f\"Restormer_{task}.zip\"\n",
        "folder_to_zip = f\"demo/sample_images/{task}\"\n",
        "\n",
        "# Using system zip command (requires zip installed)\n",
        "os.system(f\"zip -r {zip_filename} {folder_to_zip}\")\n",
        "\n",
        "if os.path.exists(zip_filename):\n",
        "    print(f\"Zip file created at: {os.path.abspath(zip_filename)}\")\n",
        "else:\n",
        "    print(\"Failed to create zip file\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch181",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
